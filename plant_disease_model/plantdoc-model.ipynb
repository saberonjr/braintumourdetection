{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29982,"status":"ok","timestamp":1712902599397,"user":{"displayName":"Christian Verra","userId":"16479958301418388037"},"user_tz":-480},"id":"j-f-RLybaQse","outputId":"3f3a0896-5e32-4a16-fce4-2a4e9fcf2f3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'PlantDoc-Object-Detection-Dataset'...\n","remote: Enumerating objects: 5196, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (4/4), done.\u001b[K\n","remote: Total 5196 (delta 2), reused 5 (delta 2), pack-reused 5190\u001b[K\n","Receiving objects: 100% (5196/5196), 941.89 MiB | 40.16 MiB/s, done.\n","Resolving deltas: 100% (2330/2330), done.\n","Updating files: 100% (5200/5200), done.\n"]}],"source":["!git clone https://github.com/saberonjr/PlantDoc-Object-Detection-Dataset.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1CTYyz2Lz42b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712911423875,"user_tz":-480,"elapsed":18577,"user":{"displayName":"Christian Verra","userId":"16479958301418388037"}},"outputId":"2bdcacf2-eb3f-47db-9b4e-21dddd709a69"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"a5mJmQBG0njH"},"source":["# **Zip the sample files**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gYtZFetHbSns"},"outputs":[],"source":["import shutil\n","\n","def zip_folder(folder_path, zip_path):\n","    shutil.make_archive(zip_path, 'zip', folder_path)\n","\n","# Specify the folder path to be zipped\n","folder_path = '/content/PlantDoc-Object-Detection-Dataset'\n","\n","# Specify the path for the zip file to be created\n","zip_path = '/content/PlantDoc-Object-Detection-Dataset.zip'\n","\n","# Call the function to zip the folder\n","zip_folder(folder_path, zip_path)"]},{"cell_type":"markdown","metadata":{"id":"r_SUPLTH0uza"},"source":["# **Copy the zip file in google drive**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"elapsed":41131,"status":"ok","timestamp":1712809703029,"user":{"displayName":"Christian Verra","userId":"06764080579308953868"},"user_tz":-480},"id":"BJtBeVAJeUfr","outputId":"4f2b6b28-a283-49ad-840b-2bf7026a4b27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/PlantDoc-Object-Detection-Dataset.zip.zip'"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["from google.colab import drive\n","import shutil\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define paths\n","zip_file_path_colab = '/content/PlantDoc-Object-Detection-Dataset.zip.zip'\n","destination_folder_drive = '/content/drive/My Drive/'\n","\n","# Copy the zip file to Google Drive\n","shutil.copy(zip_file_path_colab, destination_folder_drive)\n"]},{"cell_type":"markdown","metadata":{"id":"4W1tYdv900qM"},"source":["# **Covert xml to yolo format**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJIcUXuDJhP5"},"outputs":[],"source":["import os\n","import xml.etree.ElementTree as ET\n","\n","def convert_xml_to_yolo(xml_file, image_width, image_height):\n","    print(f\"Converting XML file: {xml_file}\")\n","\n","    root = ET.parse(xml_file).getroot()\n","    yolo_annotations = []\n","\n","    # Get image filename\n","    filename = root.find('filename').text\n","\n","    # Get image dimensions\n","    width = int(root.find('size/width').text)\n","    height = int(root.find('size/height').text)\n","\n","    if width == 0 or height == 0:\n","        print(f\"Error: Width or height is zero in XML file: {xml_file}\")\n","        return filename, []\n","\n","    # Calculate conversion factors\n","    width_ratio = image_width / width\n","    height_ratio = image_height / height\n","\n","    # Loop through object annotations\n","    for obj in root.findall('object'):\n","        # Get object class\n","        obj_class = obj.find('name').text\n","\n","        # Get bounding box coordinates\n","        xmin = int(obj.find('bndbox/xmin').text)\n","        ymin = int(obj.find('bndbox/ymin').text)\n","        xmax = int(obj.find('bndbox/xmax').text)\n","        ymax = int(obj.find('bndbox/ymax').text)\n","\n","        # Convert bounding box coordinates to YOLO format\n","        x_center = (xmin + xmax) / 2.0\n","        y_center = (ymin + ymax) / 2.0\n","        box_width = xmax - xmin\n","        box_height = ymax - ymin\n","\n","        # Normalize coordinates\n","        x_center /= width\n","        y_center /= height\n","        box_width /= width\n","        box_height /= height\n","\n","        # Append YOLO format annotation to list\n","        yolo_annotations.append(f\"{obj_class} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\")\n","\n","    return filename, yolo_annotations\n","\n","\n","def write_yolo_annotations(xml_dir, output_dir):\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    for xml_file in os.listdir(xml_dir):\n","        if xml_file.endswith('.xml'):\n","            xml_path = os.path.join(xml_dir, xml_file)\n","\n","            # Extract image dimensions\n","            tree = ET.parse(xml_path)\n","            root = tree.getroot()\n","            width = int(root.find('size/width').text)\n","            height = int(root.find('size/height').text)\n","\n","            # Convert XML to YOLO format\n","            image_filename, annotations = convert_xml_to_yolo(xml_path, width, height)\n","\n","            # Write YOLO annotations to file\n","            with open(os.path.join(output_dir, f\"{os.path.splitext(image_filename)[0]}.txt\"), 'w') as f:\n","                f.write('\\n'.join(annotations))\n","\n","# Example usage\n","xml_dir = '/content/PlantDoc-Object-Detection-Dataset/TEST'  # Directory containing XML annotations\n","output_dir = '/content/PlantDoc-Object-Detection-Dataset/main/test/labels'  # Output directory for YOLO annotations\n","write_yolo_annotations(xml_dir, output_dir)\n"]},{"cell_type":"markdown","metadata":{"id":"8kIp2_9oOmhO"},"source":["## **Removing all xml file inside the images**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1l-Gq-WmOlhO"},"outputs":[],"source":["import os\n","\n","def remove_xml_files(directory):\n","    # Get list of all files in the directory\n","    files = os.listdir(directory)\n","\n","    # Iterate over each file\n","    for file in files:\n","        # Check if the file is an XML file\n","        if file.endswith('.xml'):\n","            # Construct the full path to the XML file\n","            file_path = os.path.join(directory, file)\n","\n","            # Remove the XML file\n","            os.remove(file_path)\n","\n","# Specify the directory containing XML files\n","directory = '/content/PlantDoc-Object-Detection-Dataset/TEST'\n","\n","# Remove XML files\n","remove_xml_files(directory)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":361,"status":"ok","timestamp":1712903073585,"user":{"displayName":"Christian Verra","userId":"16479958301418388037"},"user_tz":-480},"id":"_IgA0Be0mkV0","outputId":"4178929c-4c52-4f51-970d-dcfebd7d7a21"},"outputs":[{"output_type":"stream","name":"stdout","text":["JPEG files ccopy successfully!\n"]}],"source":["import os\n","import shutil\n","\n","# Source and destination directory paths\n","source_dir = '/content/PlantDoc-Object-Detection-Dataset/TEST'\n","destination_dir = '/content/PlantDoc-Object-Detection-Dataset/main/test/images'\n","\n","# Iterate through all files and directories in the source directory\n","for root, dirs, files in os.walk(source_dir):\n","    for file in files:\n","        # Check if the file is a JPEG file\n","        if file.endswith('.jpg'):\n","            # Construct the source and destination paths\n","            source_file = os.path.join(root, file)\n","            dest_file = os.path.join(destination_dir, os.path.relpath(source_file, source_dir))\n","\n","            # Create the destination directory if it doesn't exist\n","            os.makedirs(os.path.dirname(dest_file), exist_ok=True)\n","\n","            # copy the file\n","            shutil.copy(source_file, dest_file)\n","\n","print(\"JPEG files ccopy successfully!\")\n"]},{"cell_type":"markdown","source":["# **Covert main data into rar**"],"metadata":{"id":"KUnpArdk-_-A"}},{"cell_type":"code","source":["!rar a -r PlantDoc-Object-Detection-Dataset-P.rar /content/PlantDoc-Object-Detection-Dataset/main\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKpchHe_--SK","executionInfo":{"status":"ok","timestamp":1712903215983,"user_tz":-480,"elapsed":361,"user":{"displayName":"Christian Verra","userId":"16479958301418388037"}},"outputId":"f6178374-ea33-471a-98d3-f78998148cc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: rar: command not found\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VjVgYed8PPpd"},"outputs":[],"source":["!pip install ultralytics"]},{"cell_type":"code","source":["import os\n","\n","# Directory containing the images\n","image_directory = '/content/PlantDoc-Object-Detection-Dataset/main/train/labels'\n","\n","# Get the list of files in the directory\n","files = os.listdir(image_directory)\n","\n","# Filter out only the files that have a '.jpg' extension\n","image_files = [file for file in files if file.endswith('txt')]\n","\n","# Print the number of image files\n","print(f\"Number of images: {len(image_files)}\")\n"],"metadata":{"id":"z_u2RfptK_fL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# Load a model\n","model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n","\n","# Train the model with 2 GPUs\n","results = model.train(data='/content/data2.yaml', epochs=30, imgsz=640)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DnbSpNjvX0oR","executionInfo":{"status":"ok","timestamp":1712914491901,"user_tz":-480,"elapsed":1682171,"user":{"displayName":"Christian Verra","userId":"16479958301418388037"}},"outputId":"82131a08-b12d-4beb-d050-1b148ca9c528"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.47 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/data2.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n","Overriding model.yaml nc=80 with nc=30\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    757162  ultralytics.nn.modules.head.Detect           [30, [64, 128, 256]]          \n","Model summary: 225 layers, 3016698 parameters, 3016682 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train/labels.cache... 2328 images, 10 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2328/2328 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/test/labels.cache... 239 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 239/239 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000294, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train2\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/30      2.69G      1.335      4.269      1.558         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:56<00:00,  2.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.509     0.0507     0.0397     0.0287\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/30      2.38G       1.29      3.638      1.513         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:50<00:00,  2.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.256       0.39      0.154      0.109\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/30       2.4G       1.35      3.251      1.538         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:51<00:00,  2.83it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.18it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.248      0.334      0.238      0.179\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/30      2.29G      1.308      3.031      1.507         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:52<00:00,  2.78it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.44it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.281      0.374      0.255      0.187\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/30      2.45G      1.282      2.871      1.492         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:54<00:00,  2.70it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.226      0.484      0.308      0.233\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/30       2.3G      1.272      2.713      1.481         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:53<00:00,  2.72it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.381        0.4      0.313      0.232\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/30      2.44G      1.262       2.62      1.465         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:53<00:00,  2.71it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.289      0.435      0.352      0.249\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/30      2.29G      1.248      2.524      1.451         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:53<00:00,  2.71it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.387      0.413      0.385      0.287\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/30      2.38G      1.256      2.467      1.429         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:53<00:00,  2.74it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.328      0.499      0.418      0.315\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/30      2.45G      1.233      2.417      1.429         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:52<00:00,  2.79it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.501      0.444      0.453       0.34\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      11/30      2.44G      1.232      2.349      1.431         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:50<00:00,  2.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.28it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.625      0.438       0.45      0.345\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      12/30      2.45G      1.218      2.289      1.409         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:51<00:00,  2.82it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.492      0.459      0.459      0.356\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      13/30      2.37G      1.195      2.239      1.399         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:52<00:00,  2.75it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.326      0.507      0.426      0.326\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      14/30      2.45G       1.21      2.195        1.4         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:53<00:00,  2.75it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.389      0.514       0.48      0.366\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      15/30      2.43G      1.195      2.137      1.382         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:52<00:00,  2.76it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.443      0.469      0.465      0.347\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      16/30      2.39G      1.194      2.115       1.38         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:52<00:00,  2.80it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454       0.41      0.544      0.485      0.374\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      17/30      2.37G      1.176      2.035      1.367         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:50<00:00,  2.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.399      0.554      0.504      0.387\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      18/30      2.46G      1.162      2.034      1.363         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:51<00:00,  2.83it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.21it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.469      0.516      0.515      0.397\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      19/30      2.25G      1.181      1.968      1.363         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:52<00:00,  2.79it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.491      0.529      0.528      0.404\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      20/30      2.36G      1.159       1.95      1.357         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:52<00:00,  2.79it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.427      0.565      0.511      0.399\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      21/30      2.56G      1.123      1.979      1.356         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:51<00:00,  2.85it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454       0.47      0.448      0.491      0.377\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      22/30      2.43G       1.11      1.897      1.364         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:46<00:00,  3.11it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.37it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.437      0.543      0.525      0.408\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      23/30      2.27G      1.105      1.839      1.348         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:48<00:00,  3.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.458       0.54      0.544      0.425\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      24/30      2.26G      1.099      1.803      1.338         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:46<00:00,  3.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.485      0.519      0.533      0.419\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      25/30      2.42G      1.084      1.761      1.322         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:48<00:00,  3.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.439      0.604      0.539      0.423\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      26/30      2.43G      1.073      1.721      1.315         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:47<00:00,  3.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.468      0.569      0.555       0.44\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      27/30      2.27G      1.077      1.725      1.321         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:48<00:00,  3.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.463      0.586      0.565      0.442\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      28/30      2.42G      1.066      1.695      1.327         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:46<00:00,  3.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.498      0.547      0.554      0.434\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      29/30      2.42G      1.057      1.671      1.319         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:47<00:00,  3.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.473      0.607      0.561      0.441\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      30/30      2.43G      1.051      1.631      1.305         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:47<00:00,  3.10it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.498      0.577      0.567      0.446\n","\n","30 epochs completed in 0.455 hours.\n","Optimizer stripped from runs/detect/train2/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/train2/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/train2/weights/best.pt...\n","Ultralytics YOLOv8.1.47 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 3011498 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        239        454      0.499      0.577      0.566      0.445\n","       Apple Scab Leaf        239         13      0.523      0.677      0.516      0.398\n","            Apple leaf        239         10      0.383        0.7      0.695      0.472\n","       Apple rust leaf        239         11      0.607      0.727       0.62      0.478\n"," Bell_pepper leaf spot        239         11      0.282      0.455      0.314      0.264\n","      Bell_pepper leaf        239         15      0.436      0.267      0.348      0.269\n","        Blueberry leaf        239         22       0.41      0.364      0.368      0.259\n","           Cherry leaf        239         19      0.653      0.316       0.54      0.441\n","   Corn Gray leaf spot        239          4      0.371      0.739      0.353      0.295\n","      Corn leaf blight        239         12        0.7      0.667      0.819      0.714\n","        Corn rust leaf        239         10          1      0.897      0.931      0.759\n","            Peach leaf        239         10      0.506      0.819      0.848      0.663\n","Potato leaf late blight        239         17      0.592      0.429      0.594      0.482\n","           Potato leaf        239         10       0.35        0.4      0.345      0.316\n","        Raspberry leaf        239         17      0.638          1      0.791       0.67\n","         Soyabean leaf        239         20      0.484        0.6       0.62      0.562\n","Squash Powdery mildew leaf        239          8      0.513      0.875       0.88      0.757\n","       Strawberry leaf        239         30      0.878          1      0.994      0.854\n","Tomato Early blight leaf        239         19          0          0      0.237      0.152\n","Tomato Septoria leaf spot        239         24      0.418      0.583      0.544       0.35\n","Tomato leaf bacterial spot        239         27      0.462      0.351      0.436      0.311\n","Tomato leaf late blight        239         14       0.23      0.286       0.22      0.186\n","Tomato leaf mosaic virus        239         14      0.387      0.571      0.479      0.346\n","Tomato leaf yellow virus        239         36      0.499      0.111       0.29      0.186\n","           Tomato leaf        239         42      0.588       0.69      0.647      0.326\n","      Tomato mold leaf        239         16      0.172       0.25       0.13     0.0906\n","  grape leaf black rot        239         15      0.741      0.933       0.92      0.747\n","            grape leaf        239          8      0.656      0.875      0.804       0.68\n","Speed: 0.4ms preprocess, 4.7ms inference, 0.0ms loss, 7.2ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# Load a pretrained YOLOv8n model\n","model = YOLO('/content/runs/detect/train/weights/best.pt')\n","\n","# Define path to the image file\n","source = '/content/test.jpg'\n","\n","# Run inference on the source\n","results = model(source)  # list of Results objects"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIW9gAJghHaq","executionInfo":{"status":"ok","timestamp":1712912652978,"user_tz":-480,"elapsed":480,"user":{"displayName":"Christian Verra","userId":"16479958301418388037"}},"outputId":"086677cf-b4fc-4afe-8a95-b962aaa1bd73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/test.jpg: 640x640 1 Corn leaf blight, 13.2ms\n","Speed: 3.3ms preprocess, 13.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3EWtcesGhvhC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","# Define the folder to be zipped\n","folder_to_zip = '/content/runs'\n","\n","# Define the name for the zip file\n","zip_file = '/content/runs.zip'\n","\n","# Create a ZipFile object in write mode\n","with zipfile.ZipFile(zip_file, 'w') as zipf:\n","    # Iterate over the files in the folder\n","    for root, dirs, files in os.walk(folder_to_zip):\n","        for file in files:\n","            # Define the absolute path of the file\n","            file_path = os.path.join(root, file)\n","            # Add the file to the zip archive\n","            zipf.write(file_path, os.path.relpath(file_path, folder_to_zip))\n","\n","# Print a message when the zip process is completed\n","print(f\"Folder '{folder_to_zip}' zipped successfully to '{zip_file}'.\")\n"],"metadata":{"id":"OU2gPbs5q-Q6","executionInfo":{"status":"ok","timestamp":1712914695790,"user_tz":-480,"elapsed":286,"user":{"displayName":"Christian Verra","userId":"16479958301418388037"}},"outputId":"441ab117-acc1-4397-814e-843156b4a650","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Folder '/content/runs' zipped successfully to '/content/runs.zip'.\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}